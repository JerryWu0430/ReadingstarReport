<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  <title>Implementation - ReadingStar</title>
  
  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Fonts -->
  <link href="https://fonts.googleapis.com" rel="preconnect">
  <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&family=Jost:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Main CSS File -->
  <link href="assets/css/main.css" rel="stylesheet">
  
  <!-- Syntax Highlighting -->
  <link href="assets/vendor/prism/prism.css" rel="stylesheet">
</head>

<body>

  <header id="header" class="header d-flex align-items-center sticky-top">
    <div class="container-fluid container-xl position-relative d-flex align-items-center justify-content-between">
      <a href="index.html" class="logo d-flex align-items-center">
        <h1 class="sitename">ReadingStar</h1>
      </a>
      <nav id="navmenu" class="navmenu">
        <ul>
          <li><a href="index.html">Home</a></li>
          <li><a href="requirements.html">Requirements</a></li>
          <li><a href="research.html">Research</a></li>
          <li><a href="algorithms.html">Algorithms</a></li>
          <li><a href="ui-design.html">UI Design</a></li>
          <li><a href="system-design.html">System Design</a></li>
          <li><a href="implementation.html">Implementation</a></li>
          <li><a href="testing.html">Testing</a></li>
          <li><a href="evaluation.html">Evaluation</a></li>
          <li class="dropdown"><a href="#"><span>Appendices</span> <i class="bi bi-chevron-down toggle-dropdown"></i></a>
            <ul>
              <li><a href="user-manual.html">User & Deployment Manual</a></li>
              <li><a href="gdpr-privacy.html">GDPR and Privacy of Data</a></li>
              <li><a href="development-blog.html">Development Blog</a></li>
              <li><a href="monthly-video.html">Monthly Video</a></li>
            </ul>
          </li>
        </ul>
        <i class="mobile-nav-toggle d-xl-none bi bi-list"></i>
      </nav>
    </div>
  </header>

  <main class="main">

    <!-- Overview Section -->
    <section id="overview" class="section light-background">
      <div class="container section-title" data-aos="fade-up">
        <h2>Implementation Overview</h2>
        <p>Key features and their technical implementation details</p>
      </div>
      <div class="container">
        <div class="row">
          <div class="col-lg-12" data-aos="fade-up">
            <div class="overview-content">
              <div class="tech-stack">
                <h3>Main Technologies Used</h3>
                <ul class="tech-list">
                  <li>
                    <strong>Frontend:</strong> <br> 
                    <div class="text-center">
                      <img src="assets/img/avatar.png" alt="React Native Logo" class="img-fluid mt-2" style="width: 80px; height: auto;">
                    </div>
                    <br>
                    React Native Windows - React Native is a frontend development framework based on JavaScript which enables the creation of native Windows desktop applications; the NAS schools primarily use Intel powered Windows devices. It allows for building accessible and visually engaging UI components suitable, and facilitates communication with the backend server through API requests.
                    <br>
                    <br>
                    <div class = "text-center">
                        <img src="assets/img/youtube.png" alt="YouTube Logo" class="img-fluid mt-2" style="width: 80px; height: auto;">
                    </div> <br>
                    YouTube Embed API - API by YouTube to integrate embedded video players directly into the application, allowing for the legal streaming of songs. Additionally, it provides timestamps and lyrics, useful for matching with the recognized text.
                    </li>
                  <li><strong>Backend</strong>:
                    <br>
                    <div class = "text-center">
                        <img src = "assets/img/python.png" alt = "Python Logo" class = "img-fluid mt-2" style = "width: 80px; height: auto;">
                    </div>
                    <br>
                    Python - Python is used as the backend development language for Readingstar primarily due to its extensive libraries and frameworks for streamlining the integration of AI models. Openvino pipelines, pytorch, and transformers modules in Python allowed for the efficient development and deployment of AI models into the application
                    <br>
                    <br>
                    <div class = "text-center">
                        <img src = "assets/img/fastapi.png" alt = "FastAPI Logo" class = "img-fluid mt-2" style = "width: 140px; height: auto;">
                    </div>
                    <br>
                    FastAPI serves as a framework for exposing Python functionality to the frontend through API endpoints. FastAPI was chosen over other frameworks like Django as it is faster and supports asynchronous programming, needed for handling live audio processing and serving data to the frontend in real-time. It works with an ASGI Uvicorn server for high performance handling of requests.
                  <li><strong>AI & ML:</strong>
                    <div class = "text-center">
                        <img src = "assets/img/openvino.png" alt = "OpenVINO Logo" class = "img-fluid mt-2" style = "width: 150px; height: auto;">
                    </div>
                    OpenVino - Using the OpenVino toolkit developed by Intel to optimize the inference of these AI models for faster inference on Intel hardware, where most NAS schools use Intel hardware. Provides predefined pipelines for the AI models, and increases inference speed by 3-5x. 
                    <br>
                    <br>
                    <div class = "text-center">
                        <img src = "assets/img/openai.png" alt = "OpenAI Whisper" class = "img-fluid mt-2" style = "width: 140px; height: auto;">
                    </div>
                    <br>
                    OpenAI Whisper - ASR model by OpenAI. Specifically the tiny.en model for fast transcription and focused on the english language.
                    <br>
                    <div class = "text-center">
                        <img src = "assets/img/hf.png" alt = "Transformers Logo" class = "img-fluid mt-2" style = "width: 80px; height: auto;">
                    </div>
                    <br>
                    HuggingFace AllMiniLM - Transformer based model for the semantic matching of texts. 
                    </li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Embedding Feature -->
    <section id="youtube-embed" class="section light-background">
        <div class="container section-title" data-aos="fade-up">
          <h2>YouTube Embedding & Lyric Synchronisation</h2>
          <p>Implementation of YouTube's IFrame API</p>
        </div>
        <div class="container">
          <div class="row">
            <div class="col-lg-12" data-aos="fade-up">
              <div class="feature-content">
                <div class = "feature-description">
                    <h3>Overview</h3>
                    <p>YouTube's IFrame API is used to embed YouTube videos directly into the application. Subtitles are extracted from the video along with their timestamps to display the lyrics, and a progress bar is used to enhance the interactive experience.</p>
              </div>
              <div class = "implementation-details">
                  <h3>Implementation Details</h3>
                  Firstly, the user copies the link for a YouTube video and pastes it into a url input placeholder at the top of the application.
                  <div class = "code-example">
                    <pre><code class="language-javascript">
{!isFocusMode &amp;&amp; (
    &lt;View style={styles.inputContainer}&gt;
        &lt;TextInput
            style={[
                styles.textInput,
                colorScheme === 'dark' &amp;&amp; styles.textInputDark,
            ]}
            placeholder="Paste YouTube URL here"
            placeholderTextColor={colorScheme === 'dark' ? '#ccc' : '#999'} 
            value={inputUrl} 
            onChangeText={setInputUrl} 
        /&gt;
        &lt;Pressable
            style={({ pressed }) =&gt; [
                { backgroundColor: pressed ? '#005bb5' : '#0078d4' },
                styles.goButton,
                pressed &amp;&amp; { backgroundColor: '#005bb5' },
            ]}
            onPress={() =&gt; {
                setYoutubeUrl(inputUrl);
                getYoutubeEmbedUrl(inputUrl);
            }}
        &gt;
            &lt;Text style={styles.goButtonText}&gt;Go&lt;/Text&gt;
        &lt;/Pressable&gt;
    &lt;/View&gt;
)}
                    </code></pre>
            </div>
            <div class = "code-example">
                Once the user enters the url and presses the 'Go' button, the video is embedded into the application. The entered url is stored using setYoutubeUrl state and the getYoutubeEmbedUrl function is called to extract the video id and embed the video.
                <br>
                <pre><code class="language-javascript">
const getYoutubeEmbedUrl = async (url: string): Promise<void> => {
    const videoId: string | undefined = url.split('v=')[1];
    const ampersandPosition: number = videoId ? videoId.indexOf('&') : -1;
    const finalVideoId: string | undefined = ampersandPosition !== -1 ? videoId.substring(0, ampersandPosition) : videoId;
    setEmbedUrl(`https://www.youtube.com/embed/${finalVideoId}?autoplay=1&controls=0&encrypted-media=1`);
    getSongTitle(url);
    setVideoPlaying(true);
    fetchYoutubeSubtitles(url);
    try {
        const response = await fetch('http://localhost:8000/close_microphone', {
            method: 'GET',
            headers: {
                'Content-Type': 'application/json',
            },
        });
    }
    catch (error) {}
    
    try {
        const response = await fetch('http://localhost:8000/transcribe', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
            },
        });
        
        if (!response.ok) {
            throw new Error(`HTTP error! status: ${response.status}`);
        }
        
        console.log('Transcription started');
    } catch (error) {
        console.error('Failed to start transcription:', error);
    }
};     
                </code></pre>
                <br>
                After extracting the video ID and embedding the video into the application, the getYouTubeEmbedUrl function interacts with YouTube's API to get the song title and calls fetchYoutube subtitles to fetch the subtitles for the video. The function then sends a GET request to the backend to ensure the microphone is closed before sending a POST request /transcribe to initiate the speech recognition process.
          </div>
          <div class = "code-example">
            The fetchYoutubeSubtitles function fetches the subtitles and pre-processes them to extract the lyrics and their timestamps. The lyrics are then displayed on the screen by setting the setCurrentLyric state. <br> 
            <pre><code class="language-javascript">
useEffect(() => {
    if (currentTime) {
        const elapsedTime = currentTime;

        // Find the current lyric based on elapsed time
        var currentLyric = lyrics.reduce(
            (prev, curr) => (curr.time <= elapsedTime ? curr : prev),
            { lyric: '' }
        ).lyric;


        // Only update and call startMatching if the lyric has changed
        if (currentLyric !== previousLyricRef.current) {
            console.log('Updating Lyric:', currentLyric);
            previousLyricRef.current = currentLyric; // Update previous lyric
            setCurrentLyric(currentLyric); // Update state
            startMatching(currentLyric); // Call startMatching
            checkMatch();
        }

    }
}, [currentTime, lyrics]);
            </code></pre>
            <br>
            The function also calls startMatching, providing the current lyric as a parameter. <br> 
            <pre><code class="language-javascript">
const startMatching = async (lyric : string) => {
    try {
            await fetch('http://localhost:8000/update_lyric', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
            },
            body: JSON.stringify({ lyric }),
        });
    } catch (error) {
        console.error('Error starting phrase matching:', error);
    }
}; 
            </code></pre>
            <br>
            The startMatching function sends a POST request /update_lyric to the backend to update the current lyric for the phrase matching process.
            <br> <br>
            Additionally, a sliding bar is animated to show the progress of the current phrase being displayed.
            <br>
            <pre><code class="language-javascript">
useEffect(() => {
    if (currentLyric) {
        const currentIndex = lyrics.findIndex(lyric => lyric.lyric === currentLyric);
        const nextLyric = lyrics[currentIndex + 1];
        const duration = nextLyric ? (nextLyric.time - lyrics[currentIndex].time) * 1000 : 2000;

        Animated.timing(animatedValue, {
            toValue: 1,
            duration: duration,
            useNativeDriver: false,
        }).start(() => {
            animatedValue.setValue(0);
        });
    }
}, [currentLyric]);
            </code></pre>
            <br>
            This tracks the current lyric using the timestamp and animates a sliding progress bar. Once complete, the animation resets and the next lyric is displayed.
          </div>
        </div>
      </section>
  
    <!-- Speech Recognition Feature -->
    <section id="speech-recognition" class="section">
      <div class="container section-title" data-aos="fade-up">
        <h2>Automatic Speech Recognition</h2>
        <p>Implementation of live speech recognition</p>
      </div>
      <div class="container">
        <div class="row">
          <div class="col-lg-12" data-aos="fade-up">
            <div class="feature-content">
              <div class="feature-description">
                <h3>Overview</h3>
                <p>Description of the speech recognition implementation...</p>
              </div>
              
              <div class="libraries-used">
                <h3>Libraries and APIs</h3>
                <ul>
                  <li>
                    <strong>Library Name v1.2.3</strong>
                    <p>How and why this library was used...</p>
                  </li>
                </ul>
              </div>

              <div class="implementation-details">
                <h3>Implementation Details</h3>
                <div class="code-example">
                  <pre><code class="language-javascript">
// Example code snippet
function initializeSpeechRecognition() {
    // Implementation details...
}
                  </code></pre>
                </div>
                <p>Explanation of the code implementation...</p>
              </div>

              <div class="sequence-flow">
                <h3>Process Flow</h3>
                <img src="assets/img/implementation/speech-flow.png" class="img-fluid" alt="Speech Recognition Flow">
                <p>Explanation of the process flow...</p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Audio Processing Feature -->
    <section id="audio-processing" class="section light-background">
      <div class="container section-title" data-aos="fade-up">
        <h2>Audio Processing</h2>
        <p>Implementation of audio analysis and feedback</p>
      </div>
      <div class="container">
        <div class="row">
          <div class="col-lg-12" data-aos="fade-up">
            <div class="feature-content">
              <!-- Similar structure as above -->
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Database Integration -->
    <section id="database" class="section">
      <div class="container section-title" data-aos="fade-up">
        <h2>Database Integration</h2>
        <p>Implementation of data storage and retrieval</p>
      </div>
      <div class="container">
        <div class="row">
          <div class="col-lg-12" data-aos="fade-up">
            <div class="feature-content">
              <!-- Similar structure as above -->
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- User Authentication -->
    <section id="authentication" class="section light-background">
      <div class="container section-title" data-aos="fade-up">
        <h2>User Authentication</h2>
        <p>Implementation of user management and security</p>
      </div>
      <div class="container">
        <div class="row">
          <div class="col-lg-12" data-aos="fade-up">
            <div class="feature-content">
              <!-- Similar structure as above -->
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Progress Tracking -->
    <section id="progress-tracking" class="section">
      <div class="container section-title" data-aos="fade-up">
        <h2>Progress Tracking</h2>
        <p>Implementation of user progress monitoring</p>
      </div>
      <div class="container">
        <div class="row">
          <div class="col-lg-12" data-aos="fade-up">
            <div class="feature-content">
              <!-- Similar structure as above -->
            </div>
          </div>
        </div>
      </div>
    </section>

  </main>

  <footer id="footer" class="footer">
    <div class="container copyright text-center mt-4">
      <p>Â© <span>Copyright</span> <strong class="px-1">ReadingStar</strong> <span>All Rights Reserved</span></p>
      <div class="credits">
        Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
      </div>
    </div>
  </footer>

  <a href="#" id="scroll-top" class="scroll-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <div id="preloader"></div>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/aos/aos.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/prism/prism.js"></script>

  <!-- Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>
